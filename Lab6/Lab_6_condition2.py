# -------------------------------------------------------------# Lab_6_condition2.py.py# Ієрархічна ідентифікація транспортних засобів та людей# -------------------------------------------------------------import cv2import numpy as npimport imutilsimport timeimport argparseimport sysclass VehicleAndPersonDetector:    def __init__(self, prototxt_path, model_path, conf_threshold=0.4):        # Класи MobileNetSSD        self.CLASSES = [            "background", "aeroplane", "bicycle", "bird", "boat",            "bottle", "bus", "car", "cat", "chair", "cow",            "diningtable", "dog", "horse", "motorbike", "person",            "pottedplant", "sheep", "sofa", "train", "tvmonitor"        ]        # транспортні        self.VEHICLES = {"car", "bus", "motorbike", "train"}        # люди        self.PEOPLE = {"person"}        np.random.seed(42)        self.COLORS = np.random.uniform(0, 255, size=(len(self.CLASSES), 3))        # Завантаження нейромережі        self.net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)        # Використовувати CPU        self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_DEFAULT)        self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)        print("[INFO] Використовується CPU для обчислень")        self.conf_threshold = conf_threshold        self.input_size = (500, 500)    # -------------------------------------------------------------    def classify_by_color(self, roi):        """Повертає колір транспортного засобу: light / dark / colored"""        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)        brightness = np.mean(hsv[:, :, 2])        saturation = np.mean(hsv[:, :, 1])        if brightness > 160 and saturation < 60:            return "Light vehicle (white/silver)"        if brightness < 80:            return "Dark vehicle (black/dark grey)"        return "Colored vehicle"    # -------------------------------------------------------------    def detect(self, frame):        (h, w) = frame.shape[:2]        blob = cv2.dnn.blobFromImage(            cv2.resize(frame, self.input_size),            0.007843, self.input_size, 127.5        )        self.net.setInput(blob)        detections = self.net.forward()        vehicle_count = 0        people_count = 0        for i in range(detections.shape[2]):            confidence = detections[0, 0, i, 2]            if confidence < self.conf_threshold:                continue            idx = int(detections[0, 0, i, 1])            class_name = self.CLASSES[idx]            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])            startX, startY, endX, endY = box.astype(int)            if class_name in self.VEHICLES:                vehicle_count += 1                roi = frame[startY:endY, startX:endX]                if roi.size != 0:                    color_type = self.classify_by_color(roi)                else:                    color_type = "Vehicle"                label = f"{color_type} ({class_name}) {confidence * 100:.1f}%"                cv2.rectangle(frame, (startX, startY), (endX, endY), self.COLORS[idx], 2)                cv2.putText(frame, label, (startX, startY - 10),                            cv2.FONT_HERSHEY_SIMPLEX, 0.55, self.COLORS[idx], 2)            elif class_name in self.PEOPLE:                people_count += 1                label = f"Person {confidence*100:.1f}%"                cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2)                cv2.putText(frame, label, (startX, startY - 10),                            cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 0, 255), 2)        return frame, vehicle_count, people_count# -------------------------------------------------------------if __name__ == "__main__":    ap = argparse.ArgumentParser()    ap.add_argument("-p", "--prototxt", required=True)    ap.add_argument("-m", "--model", required=True)    ap.add_argument("-c", "--confidence", type=float, default=0.3)    ap.add_argument("-v", "--video",                    default="C:\\Users\\Mishanya\\PycharmProjects\\ComputerVision_labs\\Lab6\\Video_cars_and_people.mp4")    args = vars(ap.parse_args())    detector = VehicleAndPersonDetector(args["prototxt"], args["model"], args["confidence"])    source = 0 if args["video"] == "0" else args["video"]    cap = cv2.VideoCapture(source)    if not cap.isOpened():        print("[ERROR] Не вдалося відкрити відеоджерело.")        sys.exit(1)    prev_time = time.time()    while True:        ret, frame = cap.read()        if not ret:            break        frame = imutils.resize(frame, width=900)        frame, vehicle_count, people_count = detector.detect(frame)        now = time.time()        fps = 1 / (now - prev_time)        prev_time = now        cv2.putText(frame, f"Vehicles: {vehicle_count}", (20, 30),                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)        cv2.putText(frame, f"People: {people_count}", (20, 60),                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)        cv2.putText(frame, f"FPS: {fps:.2f}", (20, 90),                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)        cv2.imshow("Vehicle and Person Detection", frame)        if cv2.waitKey(1) & 0xFF == ord("q"):            break    cap.release()    cv2.destroyAllWindows()